import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import time
import re
from urllib.parse import urljoin
import pandas as pd

class PortScheduleCrawler:
    def __init__(self):
        self.base_url = "https://www.hpnt.co.kr/infoservice/vessel/vslScheduleList.jsp"
        self.session = requests.Session()
        
        # ì‹¤ì œ ë¸Œë¼ìš°ì €ì™€ ë™ì¼í•œ í—¤ë” ì„¤ì •
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Fetch-User': '?1',
        })
    
    def get_schedule_data(self, start_date, end_date, output_format='json'):
        """
        ì›í•˜ëŠ” ë‚ ì§œ ë²”ìœ„ì˜ ì„ ì„ ë°°ì • í˜„í™©ì„ í¬ë¡¤ë§
        
        Args:
            start_date (str): ì‹œì‘ë‚ ì§œ (YYYY-MM-DD)
            end_date (str): ì¢…ë£Œë‚ ì§œ (YYYY-MM-DD) 
            output_format (str): ì¶œë ¥ í˜•ì‹ ('json', 'csv')
        """
        try:
            print(f"ğŸ” í¬ë¡¤ë§ ì‹œì‘: {start_date} ~ {end_date}")
            print("=" * 50)
            
            # 1ë‹¨ê³„: ì´ˆê¸° í˜ì´ì§€ ì ‘ì† (ê¸°ë³¸ 1ì£¼ì¼ ë°ì´í„°ê°€ ë¡œë“œë¨)
            print("1ï¸âƒ£ ì´ˆê¸° í˜ì´ì§€ ì ‘ì†...")
            initial_response = self.session.get(self.base_url)
            print(f"   âœ… ì‘ë‹µ ìƒíƒœ: {initial_response.status_code}")
            
            if initial_response.status_code != 200:
                print(f"âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {initial_response.status_code}")
                return None
        
            # í˜„ì¬ ì„¤ì •ëœ ë‚ ì§œ ë²”ìœ„ í™•ì¸
            current_dates = self._get_current_date_range(initial_response.text)
            print(f"   ğŸ“… í˜„ì¬ í˜ì´ì§€ ë‚ ì§œ: {current_dates['start']} ~ {current_dates['end']}")
            print(f"   ğŸ¯ ìš”ì²­ ë‚ ì§œ: {start_date} ~ {end_date}")
            
            # 2ë‹¨ê³„: ë‚ ì§œê°€ ë‹¤ë¥´ë©´ ìƒˆë¡œ ê²€ìƒ‰, ê°™ìœ¼ë©´ í˜„ì¬ ë°ì´í„° ì‚¬ìš©
            if current_dates['start'] == start_date and current_dates['end'] == end_date:
                print("2ï¸âƒ£ í˜„ì¬ í˜ì´ì§€ ë°ì´í„°ê°€ ìš”ì²­ ë²”ìœ„ì™€ ì¼ì¹˜ - ë°”ë¡œ íŒŒì‹±")
                result = self.parse_schedule_data(initial_response.text, output_format, start_date, end_date)
            else:
                print("2ï¸âƒ£ ë‚ ì§œ ë²”ìœ„ ë³€ê²½ í•„ìš” - ìƒˆë¡œìš´ ê²€ìƒ‰ ì‹¤í–‰")
                result = self._search_with_date_range(initial_response.text, start_date, end_date, output_format)
            
            return result
                
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None
    
    def _get_current_date_range(self, html_content):
        """í˜„ì¬ í˜ì´ì§€ì— ì„¤ì •ëœ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        start_input = soup.find('input', {'name': 'strdStDate'})
        end_input = soup.find('input', {'name': 'strdEdDate'})
        
        return {
            'start': start_input.get('value', '') if start_input else '',
            'end': end_input.get('value', '') if end_input else ''
        }
    
    def _search_with_date_range(self, html_content, start_date, end_date, output_format):
        """ìƒˆë¡œìš´ ë‚ ì§œ ë²”ìœ„ë¡œ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            print("   ğŸ” ìƒˆë¡œìš´ ë‚ ì§œ ë²”ìœ„ë¡œ ê²€ìƒ‰ ìš”ì²­...")
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # submitForm ì°¾ê¸°
            submit_form = soup.find('form', {'name': 'submitForm'})
            if not submit_form:
                print("   âŒ submitFormì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # CSRF í† í° ì¶”ì¶œ
            csrf_token = self._extract_csrf_token_from_page(soup)
            
            print(f"   ğŸ” ìµœì¢… CSRF í† í°: {csrf_token if csrf_token else 'âŒ í† í° ì—†ìŒ'}")
            
            # ê²€ìƒ‰ í¼ ë°ì´í„° êµ¬ì„±
            form_data = self._build_form_data(submit_form, start_date, end_date, csrf_token)
            print(f"   ğŸ“ ê²€ìƒ‰ ë°ì´í„° êµ¬ì„± ì™„ë£Œ")
            
            # í† í°ì´ ì—†ìœ¼ë©´ ê²½ê³  ì¶œë ¥
            if not csrf_token:
                print("CSRF í† í°ì´ ì—†ì–´ì„œ 400 ì—ëŸ¬ê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤")
                print("   ğŸ’¡ í•´ê²°ë°©ë²•: ì‚¬ì´íŠ¸ê°€ ë¡œê·¸ì¸ì„ ìš”êµ¬í•˜ê±°ë‚˜ ì¶”ê°€ ì¸ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # ê²€ìƒ‰ ìš”ì²­ ì‹¤í–‰
            response = self._submit_search_form(form_data)
            
            if response and response.status_code == 200:
                print("   âœ… ê²€ìƒ‰ ì™„ë£Œ - ê²°ê³¼ ë°ì´í„° íŒŒì‹±")
                return self.parse_schedule_data(response.text, output_format, start_date, end_date)
            else:
                print("   âŒ ê²€ìƒ‰ ì‹¤íŒ¨")
                if response:
                    print(f"   ğŸ“„ ì‘ë‹µ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {response.text[:200]}...")
                return None
                
        except Exception as e:
            print(f"   âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _extract_csrf_token_from_page(self, soup):
            """ì „ì²´ í˜ì´ì§€ì—ì„œ CSRF í† í° ì°¾ê¸° (JS ì½”ë“œ ë‚´ì—ì„œ)"""
            page_text = str(soup)
            
            # 1. ê°€ì¥ ì •í™•í•œ íŒ¨í„´: name: 'CSRF_TOKEN', value:'...' êµ¬ì¡°
            #    re.DOTALL í”Œë˜ê·¸ëŠ” ì¤„ë°”ê¿ˆ(...)ì´ ìˆì–´ë„ ì°¾ì„ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
            pattern = r"name\s*:\s*['\"]CSRF_TOKEN['\"].*?value\s*:\s*['\"]([^'\"]+)['\"]"
            
            match = re.search(pattern, page_text, re.DOTALL)
            
            if match:
                token = match.group(1)
                print(f" Â  ğŸ” JS íŒ¨í„´ 1 ì„±ê³µ: {token}")
                return token

            # 2. (í˜¹ì‹œ ëª¨ë¥¼ ì˜ˆë¹„ íŒ¨í„´) 'CSRF_TOKEN', value:'...' êµ¬ì¡°
            pattern_fallback = r"['\"]CSRF_TOKEN['\"].*?value\s*:\s*['\"]([^'\"]+)['\"]"
            match_fallback = re.search(pattern_fallback, page_text, re.DOTALL)

            if match_fallback:
                token = match_fallback.group(1)
                print(f" Â  ğŸ” JS íŒ¨í„´ 2 ì„±ê³µ: {token}")
                return token

            print(" Â  âŒ ëª¨ë“  JS íŒ¨í„´ìœ¼ë¡œ CSRF í† í° ì¶”ì¶œ ì‹¤íŒ¨")
            # <input> íƒœê·¸ ê²€ìƒ‰ì€ ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ ì œê±°
            return ''
    
    def _build_form_data(self, form, start_date, end_date, csrf_token):
        """ê²€ìƒ‰ í¼ ë°ì´í„° êµ¬ì„±"""
        # ê¸°ë³¸ ê²€ìƒ‰ ë°ì´í„°
        form_data = {
            'strdStDate': start_date,       # ì‹œì‘ë‚ ì§œ
            'strdEdDate': end_date,         # ì¢…ë£Œë‚ ì§œ
            'route': '',                    # ì„ ëª…(ROUTE) - ë¹ˆê°’ì´ë©´ ì „ì²´
            'isSearch': 'Y',                # ê²€ìƒ‰ í”Œë˜ê·¸
            'page': '1',                    # í˜ì´ì§€ ë²ˆí˜¸
            'URI': '',                      # URI
            'userID': '',                   # ì‚¬ìš©ì ID
            'groupID': 'U999',              # ê·¸ë£¹ ID
            'tmnCod': 'H'                   # í„°ë¯¸ë„ ì½”ë“œ
        }
        
        # CSRF í† í° ì¶”ê°€
        if csrf_token:
            form_data['CSRF_TOKEN'] = csrf_token
        
        # í¼ì—ì„œ ì¶”ê°€ hidden í•„ë“œë“¤ ì°¾ì•„ì„œ ì¶”ê°€
        hidden_inputs = form.find_all('input', type='hidden')
        print(f"   ğŸ” ìˆ¨ê²¨ì§„ í•„ë“œ {len(hidden_inputs)}ê°œ ë°œê²¬")
        
        for hidden in hidden_inputs:
            name = hidden.get('name')
            value = hidden.get('value', '')
            if name and name not in form_data:  # ì¤‘ë³µ ë°©ì§€
                form_data[name] = value
                print(f"      â• {name} = {value}")
        
        print(f"   ğŸ“¦ ìµœì¢… í¼ ë°ì´í„°: {len(form_data)}ê°œ í•„ë“œ")
        for key, value in form_data.items():
            if len(str(value)) > 50:  # ê¸´ ê°’ì€ ì¤„ì—¬ì„œ í‘œì‹œ
                print(f"      ğŸ“ {key} = {str(value)[:50]}...")
            else:
                print(f"      ğŸ“ {key} = {value}")
        
        return form_data
    
    def _submit_search_form(self, form_data):
        """ê²€ìƒ‰ í¼ ì œì¶œ"""
        try:
            # ìš”ì²­ í—¤ë” ì„¤ì •
            headers = {
                'Referer': self.base_url,
                'Origin': 'https://www.hpnt.co.kr',
                'Content-Type': 'application/x-www-form-urlencoded',
            }
            
            # POST ìš”ì²­ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰
            response = self.session.post(self.base_url, data=form_data, headers=headers)
            
            print(f"   ğŸ“¡ ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            if response.status_code == 200:

                return response
            else:
                print(f"   âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"   âŒ ìš”ì²­ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def parse_schedule_data(self, html_content, output_format, start_date, end_date):
        """HTMLì—ì„œ ì„ ë°• ìŠ¤ì¼€ì¤„ ë°ì´í„° íŒŒì‹±"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        print("3ï¸âƒ£ ë°ì´í„° íŒŒì‹± ì¤‘...")
        
        # ì„ ë°• ìŠ¤ì¼€ì¤„ í…Œì´ë¸” ì°¾ê¸°
        target_table = self._find_schedule_table(soup)
        
        if not target_table:
            print("   âŒ ìŠ¤ì¼€ì¤„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print("   âœ… ìŠ¤ì¼€ì¤„ í…Œì´ë¸” ë°œê²¬!")
        
        # í…Œì´ë¸”ì—ì„œ ì„ ë°• ë°ì´í„° ì¶”ì¶œ
        schedule_data = self._extract_vessel_data(target_table)
        
        if not schedule_data:
            print("   âŒ íŒŒì‹±ëœ ì„ ë°• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"   âœ… ì´ {len(schedule_data)}ê±´ì˜ ì„ ë°• ë°ì´í„° íŒŒì‹± ì™„ë£Œ!")
        
        # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
        if output_format == 'json':
            return {
                'success': True,
                'data_count': len(schedule_data),
                'period': f"{start_date} ~ {end_date}",
                'schedule_data': schedule_data,
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        else:
            return schedule_data
    
    def _find_schedule_table(self, soup):
        """ì„ ë°• ìŠ¤ì¼€ì¤„ í…Œì´ë¸” ì°¾ê¸°"""
        # ë°©ë²• 1: tblType_08 í´ë˜ìŠ¤ì˜ í…Œì´ë¸”
        table_div = soup.find('div', class_='tblType_08')
        if table_div:
            table = table_div.find('table')
            if table:
                print("   ğŸ“‹ ë°©ë²•1: tblType_08 í´ë˜ìŠ¤ë¡œ í…Œì´ë¸” ì°¾ìŒ")
                return table
        
        # ë°©ë²• 2: captionì´ "ì„ ì„ ë°°ì •í˜„í™©(ëª©ë¡)"ì¸ í…Œì´ë¸”
        captions = soup.find_all('caption')
        for caption in captions:
            if 'ì„ ì„' in caption.text and 'ë°°ì •' in caption.text:
                table = caption.find_parent('table')
                if table:
                    print("   ğŸ“‹ ë°©ë²•2: captionìœ¼ë¡œ í…Œì´ë¸” ì°¾ìŒ")
                    return table
        
        # ë°©ë²• 3: ê°€ì¥ ë§ì€ í–‰ì„ ê°€ì§„ í…Œì´ë¸” (ë°ì´í„° í…Œì´ë¸”ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)
        tables = soup.find_all('table')
        max_rows = 0
        best_table = None
        
        for table in tables:
            rows = table.find_all('tr')
            if len(rows) > max_rows and len(rows) > 5:  # ìµœì†Œ 5í–‰ ì´ìƒ
                # í…Œì´ë¸” ë‚´ìš©ì— ì„ ë°• ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                table_text = table.get_text()
                keywords = ['ì„ ëª…', 'ì„ ì‚¬', 'ì„ ì„', 'ì ‘ì•ˆ', 'ì¶œí•­']
                keyword_count = sum(1 for keyword in keywords if keyword in table_text)
                
                if keyword_count >= 3:  # 3ê°œ ì´ìƒ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì„ ë°• í…Œì´ë¸”ë¡œ íŒë‹¨
                    max_rows = len(rows)
                    best_table = table
        
        if best_table:
            print(f"   ğŸ“‹ ë°©ë²•3: ìµœëŒ€ í–‰ìˆ˜({max_rows})ì™€ í‚¤ì›Œë“œë¡œ í…Œì´ë¸” ì°¾ìŒ")
            return best_table
        
        return None
    
    def _extract_vessel_data(self, table):
        """í…Œì´ë¸”ì—ì„œ ì„ ë°• ë°ì´í„° ì¶”ì¶œ"""
        schedule_data = []
        
        # tbodyê°€ ìˆìœ¼ë©´ tbodyì—ì„œ, ì—†ìœ¼ë©´ tableì—ì„œ ì§ì ‘ tr ì¶”ì¶œ
        tbody = table.find('tbody')
        rows = tbody.find_all('tr') if tbody else table.find_all('tr')
        
        print(f"   ğŸ“Š ì´ {len(rows)}ê°œ í–‰ ë°œê²¬")
        
        # í—¤ë” í–‰ ì œì™¸í•˜ê³  ë°ì´í„° í–‰ë§Œ ì¶”ì¶œ
        data_rows = []
        for row in rows:
            if row.find('th'):  # í—¤ë” í–‰ì€ ì œì™¸
                continue
            if row.find('td'):  # ë°ì´í„°ê°€ ìˆëŠ” í–‰ë§Œ í¬í•¨
                data_rows.append(row)
        
        print(f"   ğŸ“‹ ë°ì´í„° í–‰ {len(data_rows)}ê°œ ì²˜ë¦¬")
        
        # ê° ë°ì´í„° í–‰ ì²˜ë¦¬
        for i, row in enumerate(data_rows):
            cells = row.find_all('td')
            
            # ìµœì†Œ 10ê°œ ì´ìƒì˜ ì…€ì´ ìˆì–´ì•¼ ìœ íš¨í•œ ì„ ë°• ë°ì´í„°ë¡œ íŒë‹¨
            if len(cells) < 10:
                continue
            
            try:
                # ì„ ë°• ë°ì´í„° ì¶”ì¶œ
                vessel_data = self._parse_vessel_row(row, cells)
                
                # ìœ íš¨í•œ ë°ì´í„°ì¸ì§€ í™•ì¸ (ì„ ëª…ì´ ìˆì–´ì•¼ í•¨)
                if vessel_data and vessel_data.get('ì„ ëª…', '').strip():
                    schedule_data.append(vessel_data)
                    
                    # ì§„í–‰ìƒí™© ì¶œë ¥ (10ê±´ë§ˆë‹¤)
                    if len(schedule_data) % 10 == 0:
                        print(f"   ğŸ“ˆ {len(schedule_data)}ê±´ ì²˜ë¦¬ ì™„ë£Œ...")
                
            except Exception as e:
                print(f"   âš ï¸  í–‰ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        return schedule_data
    
    def _parse_vessel_row(self, row, cells):
        """ì„ ë°• ì •ë³´ í–‰ íŒŒì‹±"""
        # row classì—ì„œ ìƒíƒœ ì •ë³´ ì¶”ì¶œ
        row_class = row.get('class', [])
        status = self._get_vessel_status(row_class)
        
        # ì…€ ê°œìˆ˜ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ë§¤í•‘
        if len(cells) >= 14:
            # í‘œì¤€ 14ê°œ ì»¬ëŸ¼ êµ¬ì¡°
            vessel_data = {
                'ì„ ì„': self.clean_text(cells[0].text),
                'ì„ ì‚¬': self.clean_text(cells[1].text),
                'ëª¨ì„ í•­ì°¨': self.clean_text(cells[2].text),
                'ì„ ì‚¬í•­ì°¨': self.clean_text(cells[3].text),
                'ì„ ëª…': self.clean_text(cells[4].text),
                'í•­ë¡œ': self.clean_text(cells[5].text),
                'ë°˜ì…ë§ˆê°ì‹œí•œ': self.clean_text(cells[6].text),
                'ì ‘ì•ˆì˜ˆì •ì¼ì‹œ': self.clean_text(cells[7].text),
                'ì¶œí•­ì˜ˆì •ì¼ì‹œ': self.clean_text(cells[8].text),
                'ì–‘í•˜': self.clean_text(cells[9].text),
                'ì í•˜': self.clean_text(cells[10].text),
                'Shift': self.clean_text(cells[11].text),
                'AMP': self.clean_text(cells[12].text),
                'ìƒíƒœ': self.clean_text(cells[13].text) or status,
            }
        else:
            # ì»¬ëŸ¼ì´ ì ì„ ê²½ìš° ê¸°ë³¸ í•„ë“œë§Œ ë§¤í•‘
            field_names = ['ì„ ì„', 'ì„ ì‚¬', 'ëª¨ì„ í•­ì°¨', 'ì„ ì‚¬í•­ì°¨', 'ì„ ëª…', 'í•­ë¡œ', 'ì ‘ì•ˆì˜ˆì •ì¼ì‹œ', 'ì¶œí•­ì˜ˆì •ì¼ì‹œ', 'ìƒíƒœ']
            vessel_data = {}
            
            for i, field in enumerate(field_names):
                if i < len(cells):
                    vessel_data[field] = self.clean_text(cells[i].text)
                else:
                    vessel_data[field] = ''
            
            if not vessel_data.get('ìƒíƒœ'):
                vessel_data['ìƒíƒœ'] = status
        
        # ë©”íƒ€ ì •ë³´ëŠ” ì œì™¸í•˜ê³  ì„ ë°• ë°ì´í„°ë§Œ ë°˜í™˜
        return vessel_data
    
    def _get_vessel_status(self, row_class):
        """row classì—ì„œ ì„ ë°• ìƒíƒœ ì¶”ì¶œ"""
        if 'color_departed' in row_class:
            return 'DEPARTED'   # ì¶œí•­ì™„ë£Œ
        elif 'color_arrived' in row_class:
            return 'ARRIVED'    # ì ‘ì•ˆì™„ë£Œ
        elif 'color_planned' in row_class:
            return 'PLANNED'    # ì˜ˆì •
        else:
            return ''
    
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if text:
            return re.sub(r'\s+', ' ', text.strip())
        return ''
    
    def save_to_file(self, data, filename, file_format='json'):
        """íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if file_format == 'json':
                with open(f"{filename}.json", 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ JSON ì €ì¥: {filename}.json")
                
            elif file_format == 'csv':
                import csv
                schedule_data = data['schedule_data'] if isinstance(data, dict) else data
                
                if schedule_data:
                    with open(f"{filename}.csv", 'w', newline='', encoding='utf-8-sig') as f:
                        writer = csv.DictWriter(f, fieldnames=schedule_data[0].keys())
                        writer.writeheader()
                        writer.writerows(schedule_data)
                    print(f"ğŸ’¾ CSV ì €ì¥: {filename}.csv")
                
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
    
    def get_summary(self, data):
        """ë°ì´í„° ìš”ì•½ ì •ë³´"""
        schedule_data = data['schedule_data'] if isinstance(data, dict) else data
        
        if not schedule_data:
            return None
        
        # ê°ì¢… í†µê³„
        berth_count = {}    # ì„ ì„ë³„
        status_count = {}   # ìƒíƒœë³„  
        shipping_count = {} # ì„ ì‚¬ë³„
        
        for vessel in schedule_data:
            # ì„ ì„ë³„ ì§‘ê³„
            berth = vessel.get('ì„ ì„', 'Unknown')
            berth_count[berth] = berth_count.get(berth, 0) + 1
            
            # ìƒíƒœë³„ ì§‘ê³„
            status = vessel.get('ìƒíƒœ', 'Unknown')
            status_count[status] = status_count.get(status, 0) + 1
            
            # ì„ ì‚¬ë³„ ì§‘ê³„
            shipping = vessel.get('ì„ ì‚¬', 'Unknown')
            shipping_count[shipping] = shipping_count.get(shipping, 0) + 1
        
        return {
            'ì „ì²´_ì„ ë°•ìˆ˜': len(schedule_data),
            'ì„ ì„ë³„_í˜„í™©': berth_count,
            'ìƒíƒœë³„_í˜„í™©': status_count,
            'ì„ ì‚¬ë³„_í˜„í™©': shipping_count
        }

def get_work_plan_data(start_date, end_date):
    """
    ì§€ì •ëœ ê¸°ê°„ì˜ ì„ ì„ ê³„íš ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        start_date (str): ì‹œì‘ì¼ (YYYY-MM-DD)
        end_date (str): ì¢…ë£Œì¼ (YYYY-MM-DD)

    Returns:
        pandas.DataFrame: í¬ë¡¤ë§ëœ ì„ ì„ ê³„íš ë°ì´í„°. ì‹¤íŒ¨ ì‹œ None.
    """
    crawler = PortScheduleCrawler()
    
    # í¬ë¡¤ë§ ì‹¤í–‰ (ë‚´ë¶€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°ì´í„° ë°›ê¸°)
    result_data = crawler.get_schedule_data(start_date, end_date, output_format='list')
    
    if result_data:
        # ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(result_data)
        print(f"âœ… í¬ë¡¤ë§ ë°ì´í„° {len(df)}ê±´ì„ DataFrameìœ¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.")

        # "ARRIVED"ì™€ "PLANNED" ìƒíƒœì˜ ë°ì´í„°ë§Œ í•„í„°ë§
        df_filtered = df[df['ìƒíƒœ'].isin(['ARRIVED', 'PLANNED'])].copy()
        print(f"âœ… 'ARRIVED', 'PLANNED' ìƒíƒœì˜ ë°ì´í„° {len(df_filtered)}ê±´ì„ í•„í„°ë§í–ˆìŠµë‹ˆë‹¤.")
        
        return df_filtered
    else:
        print("âŒ í¬ë¡¤ë§ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    
if __name__ == "__main__":
    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = datetime.now().strftime('%Y-%m-%d')
    # 7ì¼ ë’¤ ë‚ ì§œ
    end_day = (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')
    
    # 1. DataFrameìœ¼ë¡œ ë°›ê¸°
    print("--- DataFrameìœ¼ë¡œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ---")
    df = get_work_plan_data(start_date=today, end_date=end_day)
    
    if df is not None:
        print(df.head()) # ìƒìœ„ 5ê°œ ë°ì´í„° ì¶œë ¥
    
    print("\n" + "="*50 + "\n")
    
    # 2. JSONìœ¼ë¡œ ë°›ì•„ì„œ íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°
    print("--- JSONìœ¼ë¡œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ---")
    crawler_json = PortScheduleCrawler()
    json_data = crawler_json.get_schedule_data(start_date=today, end_date=end_day, output_format='json')
    
    if json_data:
        # ìš”ì•½ ì •ë³´ ì¶œë ¥
        summary = crawler_json.get_summary(json_data)
        print("\n--- ìš”ì•½ ì •ë³´ ---")
        print(json.dumps(summary, indent=2, ensure_ascii=False))
        
        # íŒŒì¼ë¡œ ì €ì¥
        crawler_json.save_to_file(json_data, "hpnt_schedule")