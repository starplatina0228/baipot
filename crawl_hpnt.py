import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import json
import time
import re
from urllib.parse import urljoin

class PortScheduleCrawler:
    def __init__(self):
        self.base_url = "https://www.hpnt.co.kr/infoservice/vessel/vslScheduleList.jsp"
        self.session = requests.Session()
        
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Fetch-User': '?1',
        })
    
    def get_schedule_data(self, start_date, end_date, output_format='json'):
        """
        Args:
            start_date (str): ì‹œì‘ë‚ ì§œ (YYYY-MM-DD)
            end_date (str): ì¢…ë£Œë‚ ì§œ (YYYY-MM-DD) 
            output_format (str): ì¶œë ¥ í˜•ì‹ ('json', 'csv')
        """
        try:
            print(f"{start_date} ~ {end_date}")
            print("=" * 50)
            
            initial_response = self.session.get(self.base_url)
            print(f"response : {initial_response.status_code}")
            
            if initial_response.status_code != 200:
                print(f"page load failure : {initial_response.status_code}")
                return None
            
            # í˜„ì¬ ì„¤ì •ëœ ë‚ ì§œ ë²”ìœ„ í™•ì¸
            current_dates = self._get_current_date_range(initial_response.text)
            print(f"í˜„ì¬ í˜ì´ì§€ ë‚ ì§œ: {current_dates['start']} ~ {current_dates['end']}")
            print(f"ìš”ì²­ ë‚ ì§œ: {start_date} ~ {end_date}")
            
            # 2ë‹¨ê³„: ë‚ ì§œê°€ ë‹¤ë¥´ë©´ ìƒˆë¡œ ê²€ìƒ‰, ê°™ìœ¼ë©´ í˜„ì¬ ë°ì´í„° ì‚¬ìš©
            if current_dates['start'] == start_date and current_dates['end'] == end_date:
                result = self.parse_schedule_data(initial_response.text, output_format, start_date, end_date)
            else:
                result = self._search_with_date_range(initial_response.text, start_date, end_date, output_format)
            
            return result
                
        except Exception as e:
            print(f"{str(e)}")
            import traceback
            print(f"{traceback.format_exc()}")
            return None
    
    def _get_current_date_range(self, html_content):
        """í˜„ì¬ í˜ì´ì§€ì— ì„¤ì •ëœ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        start_input = soup.find('input', {'name': 'strdStDate'})
        end_input = soup.find('input', {'name': 'strdEdDate'})
        
        return {
            'start': start_input.get('value', '') if start_input else '',
            'end': end_input.get('value', '') if end_input else ''
        }
    
    def _search_with_date_range(self, html_content, start_date, end_date, output_format):
        """ìƒˆë¡œìš´ ë‚ ì§œ ë²”ìœ„ë¡œ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # submitForm ì°¾ê¸°
            submit_form = soup.find('form', {'name': 'submitForm'})
            if not submit_form:
                print("submitFormì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # CSRF í† í° ì¶”ì¶œ
            csrf_token = self._extract_csrf_token(submit_form)
            
            # í† í°ì´ ì—†ìœ¼ë©´ ì „ì²´ í˜ì´ì§€ì—ì„œ ë‹¤ì‹œ ì°¾ê¸°
            if not csrf_token:
                print("submitFormì—ì„œ í† í°ì„ ì°¾ì§€ ëª»í•¨ - ì „ì²´ í˜ì´ì§€ì—ì„œ ì¬ê²€ìƒ‰")
                csrf_token = self._extract_csrf_token_from_page(soup)
            
            print(f"CSRF í† í°: {csrf_token if csrf_token else 'í† í° ì—†ìŒ'}")
            
            # ê²€ìƒ‰ í¼ ë°ì´í„° êµ¬ì„±
            form_data = self._build_form_data(submit_form, start_date, end_date, csrf_token)
            
            # ê²€ìƒ‰ ìš”ì²­ ì‹¤í–‰
            response = self._submit_search_form(form_data)
            
            if response and response.status_code == 200:
                print("ê²€ìƒ‰ ì™„ë£Œ - ê²°ê³¼ ë°ì´í„° íŒŒì‹±")
                return self.parse_schedule_data(response.text, output_format, start_date, end_date)
            else:
                print("ê²€ìƒ‰ ì‹¤íŒ¨")
                if response:
                    print(f"ì‘ë‹µ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {response.text[:200]}...")
                return None
                
        except Exception as e:
            print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _extract_csrf_token(self, form):
        """CSRF í† í° ì¶”ì¶œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)"""
        # ë°©ë²• 1: submitForm ë‚´ì—ì„œ CSRF_TOKEN input ì°¾ê¸°
        csrf_input = form.find('input', {'name': 'CSRF_TOKEN'})
        if csrf_input and csrf_input.get('value'):
            token = csrf_input.get('value')
            print(f"submitFormì—ì„œ í† í° ì¶”ì¶œ = {token}")
            return token
        
        # ë°©ë²• 2: ì „ì²´ í˜ì´ì§€ì—ì„œ CSRF_TOKEN ì°¾ê¸° (submitForm ë°–ì— ìˆì„ ìˆ˜ ìˆìŒ)
        soup = form.find_parent('html') or form.find_parent() 
        if soup:
            all_csrf_inputs = soup.find_all('input', {'name': 'CSRF_TOKEN'})
            for csrf_input in all_csrf_inputs:
                token = csrf_input.get('value', '')
                if token.strip():
                    print(f"ì „ì²´ í˜ì´ì§€ì—ì„œ í† í° ì¶”ì¶œ = {token}")
                    return token
        
        # ë°©ë²• 3: JavaScriptì—ì„œ ë™ì ìœ¼ë¡œ ì„¤ì •ëœ í† í° ì°¾ê¸°
        if hasattr(form, 'parent') and form.parent:
            page_text = str(form.parent)
            import re
            js_token_match = re.search(r"CSRF_TOKEN['\"]?\s*[,:]\s*['\"]([^'\"]+)['\"]", page_text)
            if js_token_match:
                token = js_token_match.group(1)
                print(f"JavaScriptì—ì„œ í† í° ì¶”ì¶œ = {token}")
                return token
        
        print("CSRF í† í° ì¶”ì¶œ ì‹¤íŒ¨")
        return ''
    
    def _extract_csrf_token_from_page(self, soup):
        """ì „ì²´ í˜ì´ì§€ì—ì„œ CSRF í† í° ì°¾ê¸°"""
        # ëª¨ë“  CSRF_TOKEN input íƒœê·¸ ì°¾ê¸°
        csrf_inputs = soup.find_all('input', {'name': 'CSRF_TOKEN'})
        
        print(f"í˜ì´ì§€ì—ì„œ ë°œê²¬ëœ CSRF_TOKEN input ê°œìˆ˜: {len(csrf_inputs)}")
        
        for i, csrf_input in enumerate(csrf_inputs):
            token = csrf_input.get('value', '').strip()
            form_name = 'Unknown'
            parent_form = csrf_input.find_parent('form')
            if parent_form:
                form_name = parent_form.get('name', 'Unnamed')
            
            print(f"í† í° {i+1}: '{token}' (í¼: {form_name})")
            
            if token:  # ì²« ë²ˆì§¸ ìœ íš¨í•œ í† í° ë°˜í™˜
                return token
        
        # JavaScriptì—ì„œ ë™ì  ì„¤ì • í™•ì¸
        page_text = str(soup)
        import re
        
        # íŒ¨í„´ 1: CSRF_TOKEN: 'value' ë˜ëŠ” CSRF_TOKEN': 'value'
        js_patterns = [
            r"CSRF_TOKEN['\"]?\s*:\s*['\"]([^'\"]{30,})['\"]",
            r"CSRF_TOKEN['\"]?\s*,\s*value\s*:\s*['\"]([^'\"]{30,})['\"]",
            r"name:\s*['\"]CSRF_TOKEN['\"].*?value:\s*['\"]([^'\"]{30,})['\"]"
        ]
        
        for pattern in js_patterns:
            match = re.search(pattern, page_text, re.IGNORECASE)
            if match:
                token = match.group(1)
                print(f"JavaScript íŒ¨í„´ì—ì„œ í† í° ë°œê²¬: {token}")
                return token
        
        return ''
    
    def _build_form_data(self, form, start_date, end_date, csrf_token):
        """ê²€ìƒ‰ í¼ ë°ì´í„° êµ¬ì„±"""
        # ê¸°ë³¸ ê²€ìƒ‰ ë°ì´í„°
        form_data = {
            'strdStDate': start_date,       # ì‹œì‘ë‚ ì§œ
            'strdEdDate': end_date,         # ì¢…ë£Œë‚ ì§œ
            'route': '',                    # ì„ ëª…(ROUTE) - ë¹ˆê°’ì´ë©´ ì „ì²´
            'isSearch': 'Y',                # ê²€ìƒ‰ í”Œë˜ê·¸
            'page': '1',                    # í˜ì´ì§€ ë²ˆí˜¸
            'URI': '',                      # URI
            'userID': '',                   # ì‚¬ìš©ì ID
            'groupID': 'U999',              # ê·¸ë£¹ ID
            'tmnCod': 'H'                   # í„°ë¯¸ë„ ì½”ë“œ
        }
        
        # CSRF í† í° ì¶”ê°€
        if csrf_token:
            form_data['CSRF_TOKEN'] = csrf_token
        
        # í¼ì—ì„œ ì¶”ê°€ hidden í•„ë“œë“¤ ì°¾ì•„ì„œ ì¶”ê°€
        hidden_inputs = form.find_all('input', type='hidden')
        print(f"ìˆ¨ê²¨ì§„ í•„ë“œ {len(hidden_inputs)}ê°œ ë°œê²¬")
        
        for hidden in hidden_inputs:
            name = hidden.get('name')
            value = hidden.get('value', '')
            if name and name not in form_data:  # ì¤‘ë³µ ë°©ì§€
                form_data[name] = value
                print(f"      â• {name} = {value}")
        
        print(f"ìµœì¢… í¼ ë°ì´í„°: {len(form_data)}ê°œ í•„ë“œ")
        for key, value in form_data.items():
            if len(str(value)) > 50:  # ê¸´ ê°’ì€ ì¤„ì—¬ì„œ í‘œì‹œ
                print(f"      ğŸ“ {key} = {str(value)[:50]}...")
            else:
                print(f"      ğŸ“ {key} = {value}")
        
        return form_data
    
    def _submit_search_form(self, form_data):
        """ê²€ìƒ‰ í¼ ì œì¶œ"""
        try:
            # ìš”ì²­ í—¤ë” ì„¤ì •
            headers = {
                'Referer': self.base_url,
                'Origin': 'https://www.hpnt.co.kr',
                'Content-Type': 'application/x-www-form-urlencoded',
            }
            
            # POST ìš”ì²­ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰
            response = self.session.post(self.base_url, data=form_data, headers=headers)
            
            print(f"ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            if response.status_code == 200:

                return response
            else:
                print(f"HTTP ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ìš”ì²­ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def parse_schedule_data(self, html_content, output_format, start_date, end_date):
        """HTMLì—ì„œ ì„ ë°• ìŠ¤ì¼€ì¤„ ë°ì´í„° íŒŒì‹±"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        print("ë°ì´í„° íŒŒì‹± ì¤‘...")
        
        # ì„ ë°• ìŠ¤ì¼€ì¤„ í…Œì´ë¸” ì°¾ê¸°
        target_table = self._find_schedule_table(soup)
        
        if not target_table:
            print("ìŠ¤ì¼€ì¤„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print("ìŠ¤ì¼€ì¤„ í…Œì´ë¸” ë°œê²¬!")
        
        # í…Œì´ë¸”ì—ì„œ ì„ ë°• ë°ì´í„° ì¶”ì¶œ
        schedule_data = self._extract_vessel_data(target_table)
        
        if not schedule_data:
            print("íŒŒì‹±ëœ ì„ ë°• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"{len(schedule_data)}ê±´ì˜ ì„ ë°• ë°ì´í„° íŒŒì‹±")
        
        # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
        if output_format == 'json':
            return {
                'success': True,
                'data_count': len(schedule_data),
                'period': f"{start_date} ~ {end_date}",
                'schedule_data': schedule_data,
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        else:
            return schedule_data
    
    def _find_schedule_table(self, soup):
        """ì„ ë°• ìŠ¤ì¼€ì¤„ í…Œì´ë¸” ì°¾ê¸°"""
        # ë°©ë²• 1: tblType_08 í´ë˜ìŠ¤ì˜ í…Œì´ë¸”
        table_div = soup.find('div', class_='tblType_08')
        if table_div:
            table = table_div.find('table')
            if table:
                print("tblType_08 í´ë˜ìŠ¤ë¡œ í…Œì´ë¸” ì°¾ìŒ")
                return table
        
        # ë°©ë²• 2: captionì´ "ì„ ì„ ë°°ì •í˜„í™©(ëª©ë¡)"ì¸ í…Œì´ë¸”
        captions = soup.find_all('caption')
        for caption in captions:
            if 'ì„ ì„' in caption.text and 'ë°°ì •' in caption.text:
                table = caption.find_parent('table')
                if table:
                    print("captionìœ¼ë¡œ í…Œì´ë¸” ì°¾ìŒ")
                    return table
        
        # ë°©ë²• 3: ê°€ì¥ ë§ì€ í–‰ì„ ê°€ì§„ í…Œì´ë¸” (ë°ì´í„° í…Œì´ë¸”ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)
        tables = soup.find_all('table')
        max_rows = 0
        best_table = None
        
        for table in tables:
            rows = table.find_all('tr')
            if len(rows) > max_rows and len(rows) > 5:  # ìµœì†Œ 5í–‰ ì´ìƒ
                # í…Œì´ë¸” ë‚´ìš©ì— ì„ ë°• ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                table_text = table.get_text()
                keywords = ['ì„ ëª…', 'ì„ ì‚¬', 'ì„ ì„', 'ì ‘ì•ˆ', 'ì¶œí•­']
                keyword_count = sum(1 for keyword in keywords if keyword in table_text)
                
                if keyword_count >= 3:  # 3ê°œ ì´ìƒ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì„ ë°• í…Œì´ë¸”ë¡œ íŒë‹¨
                    max_rows = len(rows)
                    best_table = table
        
        if best_table:
            print(f"ìµœëŒ€ í–‰ìˆ˜({max_rows})ì™€ í‚¤ì›Œë“œë¡œ í…Œì´ë¸” ì°¾ìŒ")
            return best_table
        
        return None
    
    def _extract_vessel_data(self, table):
        """í…Œì´ë¸”ì—ì„œ ì„ ë°• ë°ì´í„° ì¶”ì¶œ"""
        schedule_data = []
        
        # tbodyê°€ ìˆìœ¼ë©´ tbodyì—ì„œ, ì—†ìœ¼ë©´ tableì—ì„œ ì§ì ‘ tr ì¶”ì¶œ
        tbody = table.find('tbody')
        rows = tbody.find_all('tr') if tbody else table.find_all('tr')
        
        print(f"ì´ {len(rows)}ê°œ í–‰")
        
        # í—¤ë” í–‰ ì œì™¸í•˜ê³  ë°ì´í„° í–‰ë§Œ ì¶”ì¶œ
        data_rows = []
        for row in rows:
            if row.find('th'):  # í—¤ë” í–‰ì€ ì œì™¸
                continue
            if row.find('td'):  # ë°ì´í„°ê°€ ìˆëŠ” í–‰ë§Œ í¬í•¨
                data_rows.append(row)
        
        print(f"í–‰ {len(data_rows)}ê°œ ì²˜ë¦¬")
        
        # ê° ë°ì´í„° í–‰ ì²˜ë¦¬
        for i, row in enumerate(data_rows):
            cells = row.find_all('td')
            
            # ìµœì†Œ 10ê°œ ì´ìƒì˜ ì…€ì´ ìˆì–´ì•¼ ìœ íš¨í•œ ì„ ë°• ë°ì´í„°ë¡œ íŒë‹¨
            if len(cells) < 10:
                continue
            
            try:
                # ì„ ë°• ë°ì´í„° ì¶”ì¶œ
                vessel_data = self._parse_vessel_row(row, cells)
                
                # ìœ íš¨í•œ ë°ì´í„°ì¸ì§€ í™•ì¸ (ì„ ëª…ì´ ìˆì–´ì•¼ í•¨)
                if vessel_data and vessel_data.get('ì„ ëª…', '').strip():
                    schedule_data.append(vessel_data)
                    
                    # ì§„í–‰ìƒí™© ì¶œë ¥ (10ê±´ë§ˆë‹¤)
                    if len(schedule_data) % 10 == 0:
                        print(f"{len(schedule_data)}ê±´ ì²˜ë¦¬ ì™„ë£Œ...")
                
            except Exception as e:
                print(f"{i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        return schedule_data
    
    def _parse_vessel_row(self, row, cells):
        """ì„ ë°• ì •ë³´ í–‰ íŒŒì‹±"""
        # row classì—ì„œ ìƒíƒœ ì •ë³´ ì¶”ì¶œ
        row_class = row.get('class', [])
        status = self._get_vessel_status(row_class)
        
        # ì…€ ê°œìˆ˜ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ë§¤í•‘
        if len(cells) >= 14:
            # í‘œì¤€ 14ê°œ ì»¬ëŸ¼ êµ¬ì¡°
            vessel_data = {
                'ì„ ì„': self.clean_text(cells[0].text),
                'ì„ ì‚¬': self.clean_text(cells[1].text),
                'ëª¨ì„ í•­ì°¨': self.clean_text(cells[2].text),
                'ì„ ì‚¬í•­ì°¨': self.clean_text(cells[3].text),
                'ì„ ëª…': self.clean_text(cells[4].text),
                'í•­ë¡œ': self.clean_text(cells[5].text),
                'ë°˜ì…ë§ˆê°ì‹œí•œ': self.clean_text(cells[6].text),
                'ì ‘ì•ˆì˜ˆì •ì¼ì‹œ': self.clean_text(cells[7].text),
                'ì¶œí•­ì˜ˆì •ì¼ì‹œ': self.clean_text(cells[8].text),
                'ì–‘í•˜': self.clean_text(cells[9].text),
                'ì í•˜': self.clean_text(cells[10].text),
                'Shift': self.clean_text(cells[11].text),
                'AMP': self.clean_text(cells[12].text),
                'ìƒíƒœ': self.clean_text(cells[13].text) or status,
            }
        else:
            # ì»¬ëŸ¼ì´ ì ì„ ê²½ìš° ê¸°ë³¸ í•„ë“œë§Œ ë§¤í•‘
            field_names = ['ì„ ì„', 'ì„ ì‚¬', 'ëª¨ì„ í•­ì°¨', 'ì„ ì‚¬í•­ì°¨', 'ì„ ëª…', 'í•­ë¡œ', 'ì ‘ì•ˆì˜ˆì •ì¼ì‹œ', 'ì¶œí•­ì˜ˆì •ì¼ì‹œ', 'ìƒíƒœ']
            vessel_data = {}
            
            for i, field in enumerate(field_names):
                if i < len(cells):
                    vessel_data[field] = self.clean_text(cells[i].text)
                else:
                    vessel_data[field] = ''
            
            if not vessel_data.get('ìƒíƒœ'):
                vessel_data['ìƒíƒœ'] = status
        
        # ë©”íƒ€ ì •ë³´ëŠ” ì œì™¸í•˜ê³  ì„ ë°• ë°ì´í„°ë§Œ ë°˜í™˜
        return vessel_data
    
    def _get_vessel_status(self, row_class):
        """row classì—ì„œ ì„ ë°• ìƒíƒœ ì¶”ì¶œ"""
        if 'color_departed' in row_class:
            return 'DEPARTED'   # ì¶œí•­ì™„ë£Œ
        elif 'color_arrived' in row_class:
            return 'ARRIVED'    # ì ‘ì•ˆì™„ë£Œ
        elif 'color_planned' in row_class:
            return 'PLANNED'    # ì˜ˆì •
        else:
            return ''
    
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if text:
            return re.sub(r'\s+', ' ', text.strip())
        return ''
    
    def save_to_file(self, data, filename, file_format='json'):
        """íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if file_format == 'json':
                with open(f"{filename}.json", 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                print(f"JSON ì €ì¥: {filename}.json")
                
            elif file_format == 'csv':
                import csv
                schedule_data = data['schedule_data'] if isinstance(data, dict) else data
                
                if schedule_data:
                    with open(f"{filename}.csv", 'w', newline='', encoding='utf-8-sig') as f:
                        writer = csv.DictWriter(f, fieldnames=schedule_data[0].keys())
                        writer.writeheader()
                        writer.writerows(schedule_data)
                    print(f"CSV ì €ì¥: {filename}.csv")
                
        except Exception as e:
            print(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
    
    def get_summary(self, data):
        """ë°ì´í„° ìš”ì•½ ì •ë³´"""
        schedule_data = data['schedule_data'] if isinstance(data, dict) else data
        
        if not schedule_data:
            return None
        
        # ê°ì¢… í†µê³„
        berth_count = {}    # ì„ ì„ë³„
        status_count = {}   # ìƒíƒœë³„  
        shipping_count = {} # ì„ ì‚¬ë³„
        
        for vessel in schedule_data:
            # ì„ ì„ë³„ ì§‘ê³„
            berth = vessel.get('ì„ ì„', 'Unknown')
            berth_count[berth] = berth_count.get(berth, 0) + 1
            
            # ìƒíƒœë³„ ì§‘ê³„
            status = vessel.get('ìƒíƒœ', 'Unknown')
            status_count[status] = status_count.get(status, 0) + 1
            
            # ì„ ì‚¬ë³„ ì§‘ê³„
            shipping = vessel.get('ì„ ì‚¬', 'Unknown')
            shipping_count[shipping] = shipping_count.get(shipping, 0) + 1
        
        return {
            'ì „ì²´_ì„ ë°•ìˆ˜': len(schedule_data),
            'ì„ ì„ë³„_í˜„í™©': berth_count,
            'ìƒíƒœë³„_í˜„í™©': status_count,
            'ì„ ì‚¬ë³„_í˜„í™©': shipping_count
        }

def main():
    crawler = PortScheduleCrawler()
    
    start_date = "2025-07-22"
    end_date = "2025-08-25"  
    
    print(f"ì¡°íšŒ ê¸°ê°„: {start_date} ~ {end_date}")
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    result = crawler.get_schedule_data(start_date, end_date, output_format='json')
    
    if result:
        print(f"ìˆ˜ì§‘ëœ ì„ ë°• ìˆ˜: {result['data_count']}ì²™")
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"hpnt_schedule_{start_date}_to_{end_date}_{timestamp}"
        
        crawler.save_to_file(result, filename, 'json')
        crawler.save_to_file(result, filename, 'csv')
        
        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        for i, vessel in enumerate(result['schedule_data'][:5]):
            print(f"{i+1}. {vessel['ì„ ëª…']} ({vessel['ì„ ì‚¬']})")
            print(f"ì„ ì„: {vessel['ì„ ì„']} | ìƒíƒœ: {vessel['ìƒíƒœ']}")
            print(f"ì ‘ì•ˆì˜ˆì •ì¼ì‹œ: {vessel.get('ì ‘ì•ˆì˜ˆì •ì¼ì‹œ', 'N/A')}")
            print(f"ì¶œí•­ì˜ˆì •ì¼ì‹œ: {vessel.get('ì¶œí•­ì˜ˆì •ì¼ì‹œ', 'N/A')}")
    else:
        print("\nfailure")

if __name__ == "__main__":
    print("HPNT")
    print("=" * 60)
    main()